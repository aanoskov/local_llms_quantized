This repository demonstrates some of SOTA LLM models which could be inferred without any huge hardware requirements
Local_LLMs_HW_reqs.ipynb - deployment of Local LLMs and calculating hw specific metrics
Local_LLMs_Eval.ipynb - Notebook with Evalution of Quantized models
Local_LLMs_pres.pptx
report.docx
